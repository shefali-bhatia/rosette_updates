{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sys\n",
    "from antlr4 import *\n",
    "from grammar.SQLiteLexer import SQLiteLexer\n",
    "from grammar.SQLiteParser import SQLiteParser\n",
    "from grammar.SQLiteListener import SQLiteListener\n",
    "import re\n",
    "from readlisp import readlisp, LispSymbol\n",
    "import copy\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_process_tree(filename):\n",
    "    with open(filename) as f:\n",
    "        lines = []\n",
    "        for line in f.readlines():\n",
    "            if \"like\" in line.lower():\n",
    "                new_line = re.sub(\"\"\"(?!\\()([^\\s]+?\\s+?(?:not\\s)?like\\s+?[\"'][^\\s]+?[\"'])\\s+?(?!\\))\"\"\", r' (\\1) ', line, flags = re.IGNORECASE)\n",
    "                # print(re.findall(\"\"\"(?!\\()([^\\s]+?\\s+?(?:not\\s)?like\\s+?[\"'][^\\s]+?[\"'])\\s+?(?!\\))\"\"\", line, flags = re.IGNORECASE))\n",
    "                lines.append(new_line)\n",
    "            else:\n",
    "                lines.append(line)\n",
    "    with open(filename, \"w+\") as f:\n",
    "        f.writelines(lines)\n",
    "        \n",
    "def remove_lisp_symbol(l):\n",
    "    if type(l) in [LispSymbol, int, float]:\n",
    "        if type(l) == LispSymbol:\n",
    "            return l.name.lower()\n",
    "        else:\n",
    "            return str(l)\n",
    "    elif type(l) == list:\n",
    "        return [remove_lisp_symbol(ls) for ls in l]\n",
    "    else:\n",
    "        print(\"Uhoh\", type(l), l)\n",
    "        \n",
    "def get_parsed_tree(filename):\n",
    "    pre_process_tree(filename)\n",
    "    input_stream = FileStream(filename)\n",
    "    lexer = SQLiteLexer(input_stream)\n",
    "    stream = CommonTokenStream(lexer)\n",
    "    parser = SQLiteParser(stream)\n",
    "    tree = parser.parse()\n",
    "    tree = remove_lisp_symbol(readlisp(tree.toStringTree(recog=parser)))\n",
    "    return tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "test1 = get_parsed_tree(\"test1.sql\")\n",
    "test2 = get_parsed_tree(\"test2.sql\")\n",
    "test3 = get_parsed_tree(\"test3.sql\")\n",
    "test4 = get_parsed_tree(\"test4.sql\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['factored_select_stmt',\n",
       " ['select_core',\n",
       "  'select',\n",
       "  ['result_column',\n",
       "   ['expr',\n",
       "    ['table_name', ['any_name', 'c1']],\n",
       "    '.',\n",
       "    ['column_name', ['any_name', 'cand_name']]]],\n",
       "  ',',\n",
       "  ['result_column',\n",
       "   ['expr',\n",
       "    ['table_name', ['any_name', 'c2']],\n",
       "    '.',\n",
       "    ['column_name', ['any_name', 'cmte_nm']]]],\n",
       "  'from',\n",
       "  ['join_clause',\n",
       "   ['table_or_subquery',\n",
       "    ['table_name', ['any_name', 'cand']],\n",
       "    ['table_alias', 'c1']],\n",
       "   ['join_operator', 'inner', 'join'],\n",
       "   ['table_or_subquery',\n",
       "    ['table_name', ['any_name', 'comm']],\n",
       "    ['table_alias', 'c2']],\n",
       "   ['join_constraint',\n",
       "    'on',\n",
       "    ['expr',\n",
       "     ['expr',\n",
       "      ['table_name', ['any_name', 'c1']],\n",
       "      '.',\n",
       "      ['column_name', ['any_name', 'cand_id']]],\n",
       "     '=',\n",
       "     ['expr',\n",
       "      ['table_name', ['any_name', 'c2']],\n",
       "      '.',\n",
       "      ['column_name', ['any_name', 'cand_id']]]]]]],\n",
       " 'order',\n",
       " 'by',\n",
       " ['ordering_term',\n",
       "  ['expr',\n",
       "   ['table_name', ['any_name', 'c1']],\n",
       "   '.',\n",
       "   ['column_name', ['any_name', 'cand_name']]],\n",
       "  'desc'],\n",
       " 'limit',\n",
       " ['expr', ['literal_value', '5']]]"
      ]
     },
     "execution_count": 372,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "select_s_exp_3 = test3[1][1][1]\n",
    "select_s_exp_4 = test4[1][1][1]\n",
    "select_s_exp_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from pprint import pprint\n",
    "\n",
    "def gen_fresh_name(base_name, used_names):\n",
    "    if base_name not in used_names:\n",
    "        new_name = base_name\n",
    "    else:\n",
    "        for i in range(2, 10000):\n",
    "            if f\"{base_name}_{i}\" in used_names:\n",
    "                continue\n",
    "            new_name = f\"{base_name}_{i}\"\n",
    "            break\n",
    "    used_names.append(new_name)\n",
    "    return new_name\n",
    "\n",
    "def gen_name_mapping(old_name_sets, new_names):\n",
    "    # old names is a list of set\n",
    "    # new names is a list of strings\n",
    "    mapping = {}\n",
    "    for old_names, new_name in zip(old_name_sets, new_names):\n",
    "      for old_name in old_names:\n",
    "        mapping[old_name] = new_name\n",
    "    return mapping\n",
    "    \n",
    "class TableOp():\n",
    "    def tbl_op_dispatcher(s_exp):\n",
    "        print(s_exp)\n",
    "        if s_exp[0] == \"table_or_subquery\":\n",
    "            if s_exp[1][0] == 'table_name':\n",
    "                print(\"dispatching to tbl_ref\")\n",
    "                return TableReference(s_exp)\n",
    "            else:\n",
    "                print(\"dispatching to select statement\")\n",
    "                return SelectStatement(s_exp[1][0])\n",
    "        elif s_exp[0] == \"join_clause\":\n",
    "            print(\"dispatching to join\")\n",
    "            return JoinTable.from_s_exp(s_exp)\n",
    "        \n",
    "        \n",
    "class RenamedTable(TableOp):\n",
    "    def __init__(self, name, table, cols):\n",
    "        self.name = name\n",
    "        self.table = table\n",
    "        self.cols = cols # these are invented alias names \n",
    "\n",
    "    def infer_out_schema(self, schema):\n",
    "        return self.table.infer_out_schema(schema)\n",
    "\n",
    "    def rename(self, schema, used_table_names):\n",
    "        return self.table.rename(schema, used_table_names)\n",
    "    \n",
    "    def rename_ops(self, mapping):\n",
    "        pass\n",
    "    \n",
    "    def to_rkt(self, schema):\n",
    "        return \"(AS \" + self.table.to_rkt(schema) + \"\\n[\\\"\" + self.name + \"\\\" (list \" + \" \".join([\"\\\"\" + col + \"\\\"\" for col in self.cols]) + \")])\"\n",
    "            \n",
    "class TableReference(TableOp):\n",
    "    def __init__(self, s_exp):\n",
    "        self.name = s_exp[1][1][1]\n",
    "        if len(s_exp) > 2:\n",
    "            self.alias = s_exp[2][1]\n",
    "        else:\n",
    "            self.alias = None\n",
    "            \n",
    "    def infer_out_schema(self, schema):\n",
    "        tbl_schema = schema[self.name]\n",
    "        to_return = []\n",
    "        for col in tbl_schema:\n",
    "            full_name = self.alias + \".\" + col if self.alias else self.name + \".\" + col\n",
    "            to_return.append(set([full_name, col]))\n",
    "        \n",
    "        print(\"returning\", to_return)\n",
    "        return to_return\n",
    "\n",
    "    def rename(self, schema, used_table_names):\n",
    "        tbl_schema = schema[self.name]\n",
    "        tbl_name = self.alias if self.alias else self.name\n",
    "        \n",
    "        new_table_name = gen_fresh_name(tbl_name, used_table_names)\n",
    "        \n",
    "        # collecting old names\n",
    "        old_names = [set([c, f\"{tbl_name}.{c}\"]) for c in tbl_schema]\n",
    "        new_names = [f\"{new_table_name}.{c}\" for c in tbl_schema]\n",
    "      \n",
    "        mappings = gen_name_mapping(old_names, new_names)\n",
    "        \n",
    "        return RenamedTable(new_table_name, self, list(tbl_schema.keys())), mappings, used_table_names\n",
    "\n",
    "    def rename_ops(self, mapping):\n",
    "        pass\n",
    "    \n",
    "    def to_rkt(self, schema):\n",
    "        return \"(NAMED \" + self.name + \")\"\n",
    "\n",
    "        \n",
    "class JoinTable(TableOp):\n",
    "    def __init__(self, left_tbl, right_tbl, join_op, constraint = None):\n",
    "        self.left_tbl = left_tbl\n",
    "        self.right_tbl = right_tbl\n",
    "        self.join_op = join_op\n",
    "        self.constraint = constraint\n",
    "        \n",
    "    @classmethod\n",
    "    def from_s_exp(cls, s_exp):\n",
    "        left_tbl = TableOp.tbl_op_dispatcher(s_exp[1])\n",
    "        join_op = s_exp[2][1:]\n",
    "        right_tbl = TableOp.tbl_op_dispatcher(s_exp[3])\n",
    "        if \"inner\" in join_op:\n",
    "            print(\"Wrapping inner table as select\")\n",
    "            if type(s_exp[4]) == list:\n",
    "                constraint = PredicateOp.pred_op_dispatcher(s_exp[4])\n",
    "            else:\n",
    "                constraint = None\n",
    "            cross_table = cls(left_tbl, right_tbl, 'cross')\n",
    "            to_return = SelectStatement([], wrap = True, wrap_tbl = cross_table, wrap_constraints = constraint)\n",
    "            return to_return\n",
    "        else:\n",
    "            if type(s_exp[4]) == list:\n",
    "                constraint = PredicateOp.pred_op_dispatcher(s_exp[4])\n",
    "            else:\n",
    "                constraint = None\n",
    "            return cls(left_tbl, right_tbl, join_op, constraint)\n",
    "\n",
    "    def infer_out_schema(self, schema):        \n",
    "        left_cols = self.left_tbl.infer_out_schema(schema)\n",
    "        right_cols = self.right_tbl.infer_out_schema(schema)\n",
    "        left_cols_set = set()\n",
    "        right_cols_set = set()\n",
    "        for col_set in left_cols:\n",
    "             left_cols_set = left_cols_set.union(col_set)\n",
    "        for col_set in right_cols:\n",
    "             right_cols_set = right_cols_set.union(col_set)\n",
    "        duplicate_col_names = left_cols_set & right_cols_set\n",
    "        \n",
    "        if hasattr(self, \"alias\") and self.alias:\n",
    "            name = tbl.alias\n",
    "        else:\n",
    "            name = None\n",
    "        \n",
    "        used_names = set()\n",
    "        non_referrables = [set() for i in range(len(left_cols + right_cols))]\n",
    "        for index, colset in enumerate(left_cols + right_cols):\n",
    "            for col_name in colset:\n",
    "                if col_name in used_names:\n",
    "                    non_referrables[index].add(col_name)\n",
    "                else:\n",
    "                    used_names.add(col_name)\n",
    "            \n",
    "        to_return = left_cols + right_cols\n",
    "        if not name:\n",
    "            to_return = [{c for c in nameset if c not in non_refs} for nameset, non_refs in zip(to_return, non_referrables)]\n",
    "        else:\n",
    "            to_return = [set([f'{name}.{c}' for c in nameset if c not in non_refs and \".\" not in c] \n",
    "                             + [c for c in nameset if c not in non_refs and '.' in c]) for nameset, non_refs in zip(to_return, non_referrables)]\n",
    "#         for index, nameset in enumerate(left_cols):\n",
    "#             for col in nameset:\n",
    "#                 if col in duplicate_col_names:\n",
    "#                     if name:\n",
    "#                         to_return[index].union(set([col, name + \".\" + col]))\n",
    "#                     else:\n",
    "#                         to_return[index].union(set([col]))\n",
    "        \n",
    "        print(\"Inferring join, returning\", to_return)\n",
    "        return to_return\n",
    "    \n",
    "    \n",
    "    def rename(self, schema, used_table_names):\n",
    "        left_cols_old = self.left_tbl.infer_out_schema(schema)\n",
    "        right_cols_old = self.right_tbl.infer_out_schema(schema)\n",
    "        my_cols_old = self.infer_out_schema(schema)\n",
    "        \n",
    "        self.left_tbl, mappings_left, used_table_names = self.left_tbl.rename(schema, used_table_names)\n",
    "        self.right_tbl, mappings_right, used_table_names = self.right_tbl.rename(schema, used_table_names)\n",
    "        \n",
    "        left_cols_new = self.left_tbl.infer_out_schema(schema)\n",
    "        right_cols_new = self.right_tbl.infer_out_schema(schema)\n",
    "        \n",
    "        self.rename_ops({**mappings_left, **mappings_right})\n",
    "        \n",
    "        new_table_name = gen_fresh_name(self.alias if (hasattr(self, \"alias\") and self.alias) else \"t\", used_table_names)\n",
    "        \n",
    "        mappings = {}        \n",
    "        # the list of new names\n",
    "        column_list = []\n",
    "        used_col_names = []\n",
    "        for index, col_set in enumerate(my_cols_old):\n",
    "            old_full_name = [col for col in col_set if \".\" in col]\n",
    "            old_short_name = [col for col in col_set if \".\" not in col]\n",
    "            base_name = old_full_name[0].split(\".\")[-1] if len(old_full_name) > 0 else \"c\"\n",
    "            new_name = gen_fresh_name(base_name, used_col_names)\n",
    "            \n",
    "            for old_name in col_set:\n",
    "                mappings[old_name] = new_table_name + \".\" + new_name\n",
    "            column_list.append(new_name)\n",
    "            \n",
    "        print(\"My mapping from join:\")\n",
    "        pprint(mappings)\n",
    "      \n",
    "        return RenamedTable(new_table_name, self, column_list), mappings, used_table_names \n",
    "\n",
    "    def rename_ops(self, mapping):\n",
    "        if self.constraint:\n",
    "            self.constraint.rename_ops(mapping)\n",
    "            \n",
    "    def to_rkt(self, schema):\n",
    "        if \"left\" in self.join_op:\n",
    "            op = \"LEFT-OUTER-JOIN\"\n",
    "        else:\n",
    "            op = \"JOIN\"\n",
    "             \n",
    "        return f\"({op} {self.left_tbl.to_rkt(schema)} {self.right_tbl.to_rkt(schema)} {self.constraint.to_rkt(schema) if self.constraint else ''})\"\n",
    "    \n",
    "\n",
    "class SelectStatement(TableOp):\n",
    "    def __init__(self, entire_s_exp, wrap = False, wrap_tbl = None, wrap_constraints = None):\n",
    "        if wrap:\n",
    "            self.columns = [AllColumn()]\n",
    "            self.col_names = [None]\n",
    "            self.tables = [wrap_tbl]\n",
    "            self.tbl_names = [None]\n",
    "            self.subquery_tree = wrap_tbl\n",
    "            self.where_tree = wrap_constraints\n",
    "            self.group_col = None\n",
    "            self.having_tree = None\n",
    "            self.order_cols = []\n",
    "            self.ordering_dir = []\n",
    "        else:\n",
    "            self.from_s_exp(entire_s_exp)\n",
    "\n",
    "    \n",
    "    def from_s_exp(self, entire_s_exp):\n",
    "        s_exp = entire_s_exp[1]\n",
    "\n",
    "        select_index = s_exp.index('select')\n",
    "        from_index = s_exp.index('from')\n",
    "        self.columns = []\n",
    "        self.col_names = []\n",
    "        for term in s_exp[select_index:from_index]:\n",
    "            if type(term) == list and term[0] == 'result_column':\n",
    "                self.columns.append(ColOp.col_op_dispatcher(term[1]))\n",
    "                if \"as\" in term:\n",
    "                    alias = term[term.index(\"as\") + 1][1]\n",
    "                    self.col_names.append(alias)\n",
    "                else:\n",
    "                    self.col_names.append(None)\n",
    "\n",
    "        self.tables = []\n",
    "        self.tbl_names = [] \n",
    "        if \"where\" in s_exp:\n",
    "            where_index = s_exp.index('where')\n",
    "            for term in s_exp[from_index+1:where_index]:\n",
    "                if type(term) == list:\n",
    "                    self.tables.append(TableOp.tbl_op_dispatcher(term))\n",
    "                if \"as\" in term:\n",
    "                    alias = term[term.index(\"as\") + 1][1]\n",
    "                    self.tbl_names.append(alias)\n",
    "                else:\n",
    "                    self.tbl_names.append(None)\n",
    "        else:\n",
    "            for term in s_exp[from_index+1:]:\n",
    "                if type(term) == list:\n",
    "                    self.tables.append(TableOp.tbl_op_dispatcher(term))\n",
    "                if \"as\" in term:\n",
    "                    alias = term[term.index(\"as\") + 1][1]\n",
    "                    self.tbl_names.append(alias)\n",
    "                else:\n",
    "                    self.tbl_names.append(None)\n",
    "\n",
    "        if len(self.tables) > 1:\n",
    "            self.tables[0].alias = self.tbl_names[0]\n",
    "            self.tables[1].alias = self.tbl_names[1]\n",
    "            self.subquery_tree = JoinTable(self.tables[0], self.tables[1], 'cross')\n",
    "            if len(self.tables) > 2:\n",
    "                for i, tbl in enumerate(self.tables[2:]):\n",
    "                    tbl.alias = self.tbl_names[i+2]\n",
    "                    self.subquery_tree = JoinTable(left_tbl = self.subquery_tree, right_tbl = tbl, join_op = 'cross')\n",
    "        else:\n",
    "            self.subquery_tree = self.tables[0]\n",
    "            self.subquery_tree.alias = self.tbl_names[0]\n",
    "\n",
    "        if \"where\" in s_exp:\n",
    "            self.where_tree = PredicateOp.pred_op_dispatcher(s_exp[where_index+1])\n",
    "        else:\n",
    "            self.where_tree = None\n",
    "\n",
    "        if \"group\" in s_exp:\n",
    "            groupby_index = list(filter(lambda i: s_exp[i] == 'group' and s_exp[i+1] == 'by', range(len(s_exp)-2)))[0]\n",
    "            if \"having\" in s_exp:  \n",
    "                having_index = s_exp.index('having')\n",
    "                self.group_col = [ColOp.col_op_dispatcher(col) for col in s_exp[groupby_index + 2:having_index]]\n",
    "            else:\n",
    "                self.group_col = [ColOp.col_op_dispatcher(col) for col in s_exp[groupby_index + 2:]]\n",
    "        else:\n",
    "            self.group_col = None\n",
    "        \n",
    "        if \"having\" in s_exp:\n",
    "            having_index = s_exp.index('having')\n",
    "            self.having_tree = PredicateOp.pred_op_dispatcher(s_exp[having_index+1])\n",
    "        else:\n",
    "            self.having_tree = None\n",
    "\n",
    "        self.order_cols = []\n",
    "        self.ordering_dir = []\n",
    "        if 'order' in entire_s_exp:\n",
    "            orderby_index = list(filter(lambda i: entire_s_exp[i] == 'order' and entire_s_exp[i+1] == 'by', range(len(entire_s_exp)-2)))[0]\n",
    "            if \"limit\" in entire_s_exp:\n",
    "                end = entire_s_exp.index('limit')\n",
    "            else:\n",
    "                end = len(entire_s_exp)\n",
    "            for term in entire_s_exp[orderby_index+2:end]:\n",
    "                if type(term) == list and term[0] == \"ordering_term\":\n",
    "                    self.order_cols.append(ColOp.col_op_dispatcher(term[1]))\n",
    "                    if len(term) > 2:\n",
    "                        self.ordering_dir.append(term[2])\n",
    "                    else:\n",
    "                        self.ordering_dir.append(\"asc\")\n",
    "\n",
    "        if 'limit' in entire_s_exp:\n",
    "            limit_index = entire_s_exp.index('limit')\n",
    "            self.limit = entire_s_exp[limit_index+1][1][1]\n",
    "\n",
    "    \n",
    "    def infer_out_schema(self, schema):\n",
    "        to_return = []\n",
    "        if type(self.columns[0]) == AllColumn:\n",
    "            schema = self.subquery_tree.infer_out_schema(schema)\n",
    "            to_return = [{col for col in nameset if \".\" not in col} for nameset in schema]\n",
    "        else:\n",
    "            for col, col_name in zip(self.columns, self.col_names):\n",
    "                if col_name:\n",
    "                    to_return.append(set([col_name]))\n",
    "                else:\n",
    "                    if type(col) in [UnaryColumnOp, BinaryColumnOp, ConstantColumn]:\n",
    "                        to_return.append(set())\n",
    "                    else:\n",
    "                        to_return.append(set([col.name]))\n",
    "                    \n",
    "        if hasattr(self, \"alias\") and self.alias:\n",
    "            for col in to_return:\n",
    "                if col:\n",
    "                    col.add(self.alias + \".\" + next(iter(col)))\n",
    "        print(\"Inferring select, returning\", to_return)\n",
    "        return to_return\n",
    "\n",
    "    def rename(self, schema, used_table_names):\n",
    "        child_old_names = self.subquery_tree.infer_out_schema(schema)\n",
    "        my_old_names = self.infer_out_schema(schema)\n",
    "        \n",
    "        self.subquery_tree, child_mappings, used_table_names = self.subquery_tree.rename(schema, used_table_names)\n",
    "        child_new_names = self.subquery_tree.infer_out_schema(schema)\n",
    "        \n",
    "        # only rename ops in select and where, ops in having should be renamed using my_mappings instead of mappings\n",
    "        self.rename_ops(child_mappings)\n",
    "        print(\"My child old names are\", child_old_names)\n",
    "        new_table_name = gen_fresh_name(self.alias if (hasattr(self, \"alias\") and self.alias) else \"t\", used_table_names)\n",
    "        print(\"my old names are\", my_old_names)\n",
    "        mappings = {}\n",
    "        column_list = []\n",
    "        used_col_names = []\n",
    "        #print(\"My old names are\", old_names)\n",
    "        for index, col_set in enumerate(my_old_names):\n",
    "            old_full_name = [col for col in col_set if \".\" in col]\n",
    "            old_short_name = [col for col in col_set if \".\" not in col]\n",
    "            if len(old_full_name) > 0:\n",
    "                base_name = old_full_name[0]\n",
    "            elif len(old_short_name) > 0:\n",
    "                base_name = old_short_name[0]\n",
    "            else:\n",
    "                base_name = 'c'\n",
    "            new_name = gen_fresh_name(base_name, used_col_names)\n",
    "\n",
    "            for old_name in col_set:\n",
    "                mappings[old_name] = new_table_name + \".\" + new_name\n",
    "\n",
    "            column_list.append(new_name)\n",
    "          \n",
    "        print(f\"My mapping is [Select {new_table_name}]:\")\n",
    "        pprint(mappings)\n",
    "        \n",
    "        # old names overwrites new names\n",
    "        mappings_copy = copy.deepcopy(mappings)\n",
    "        for name in child_mappings:\n",
    "            mappings_copy[name] = child_mappings[name]\n",
    "        \n",
    "        # self.rename_having(mappings_copy)\n",
    "        \n",
    "        return RenamedTable(new_table_name, self, column_list), mappings, used_table_names\n",
    "\n",
    "    def rename_ops(self, mapping):\n",
    "        replacement_col_names = []\n",
    "        if type(self.columns[0]) == AllColumn:\n",
    "            print(\"Renaming inner table\")\n",
    "            pass\n",
    "        else:\n",
    "            for col in self.columns:\n",
    "                col.rename_ops(mapping)\n",
    "\n",
    "        if self.where_tree:\n",
    "            self.where_tree.rename_ops(mapping)\n",
    "\n",
    "        if self.group_col:\n",
    "            for col in self.group_col:\n",
    "                col.rename_ops(mapping) \n",
    "                \n",
    "    def rename_having(self, mapping):\n",
    "        if self.having_tree:\n",
    "            self.having_tree.rename_ops(mapping)\n",
    "\n",
    "        for col in self.order_cols:\n",
    "            col.rename_ops(mapping)\n",
    "            \n",
    "    def to_rkt(self, schema):\n",
    "        where_part = \"\\nWHERE \" + self.where_tree.to_rkt(schema) if self.where_tree else \"\"\n",
    "        group_part = \"\\nGROUP-BY (list \" + \" \".join([col.to_rkt(schema) + \" \" for col in self.group_col])+ \")\" if self.group_col else \"\"\n",
    "        having_part = \"\\nHAVING \" + self.having_tree.to_rkt(schema) if self.having_tree else \"\"\n",
    "        \n",
    "        return \"(SELECT \" + \"(VALS \" + \" \".join([col.to_rkt(schema) for col in self.columns]) + \")\" + \"\\nFROM \" + self.subquery_tree.to_rkt(schema) + where_part + \" \" + group_part + \" \" + having_part + \")\"\n",
    "            \n",
    "\n",
    "class ColOp():\n",
    "    def col_op_dispatcher(s_exp):\n",
    "        print(s_exp)\n",
    "        if s_exp == \"*\" or s_exp == \"[*]\":\n",
    "            print(\"dispatching to *\")\n",
    "            return AllColumn()\n",
    "        assert s_exp[0] == \"expr\"\n",
    "        if s_exp[1][0] == \"column_name\":\n",
    "            print(\"dispatching to col name\")\n",
    "            return Column(s_exp[1])\n",
    "        elif s_exp[1][0] == \"literal_value\":\n",
    "            print(\"dispatching to col value\")\n",
    "            return ConstantColumn(s_exp[1])\n",
    "        elif s_exp[1][0] == \"function_name\" and len(s_exp) == 3:\n",
    "            print(\"dispatching to unary\")\n",
    "            return UnaryColumnOp(s_exp)\n",
    "        elif '.' in s_exp:\n",
    "            print(\"dispatching to col name\")\n",
    "            return Column(s_exp, table = True)\n",
    "        elif len(s_exp) == 4:\n",
    "            print(\"dispatching to binary\")\n",
    "            return BinaryColumnOp(s_exp)       \n",
    "\n",
    "class Column(ColOp):\n",
    "    def __init__(self, s_exp, table = False):\n",
    "        if not table:\n",
    "            assert s_exp[0] == \"column_name\"\n",
    "            self.name = s_exp[1][1]\n",
    "            self.table = None\n",
    "        else:\n",
    "            assert s_exp[1][0] == \"table_name\"\n",
    "            self.name = s_exp[3][1][1]\n",
    "            self.table = s_exp[1][1][1]\n",
    "\n",
    "    def rename_ops(self, mapping):\n",
    "        if self.table:\n",
    "            new_name = mapping[self.table + \".\" + self.name] \n",
    "            self.table = new_name.split(\".\")[0]\n",
    "            self.name = new_name.split(\".\")[1]\n",
    "        else:\n",
    "            new_name = mapping[self.name] \n",
    "            self.name = new_name.split(\".\")[1]\n",
    "       \n",
    "      \n",
    "    def to_rkt(self, schema):\n",
    "        return \"\\\"\" + (self.table + \".\" + self.name if self.table else self.name) + \"\\\"\"\n",
    "        \n",
    "        \n",
    "class ConstantColumn(ColOp):\n",
    "    def __init__(self, s_exp):\n",
    "        assert s_exp[0] == \"literal_value\"\n",
    "        self.value = s_exp[1]\n",
    "        \n",
    "    def to_rkt(self, schema):\n",
    "        return str(self.value)\n",
    "    \n",
    "    def rename_ops(self, mapping, tbl_name):\n",
    "        pass\n",
    "    \n",
    "class UnaryColumnOp(ColOp):\n",
    "    def __init__(self, s_exp):\n",
    "        self.op = s_exp[1][1][1]\n",
    "        self.col_ops = []\n",
    "        for child in s_exp[2]:\n",
    "            self.col_ops.append(ColOp.col_op_dispatcher(child))\n",
    "\n",
    "    def rename_ops(self, mapping):\n",
    "        for child in self.col_ops:\n",
    "            child.rename_ops(mapping)\n",
    "            \n",
    "    def to_rkt(self, schema):\n",
    "        return \"(\" + self.op + \" \" + \" \".join([\"\\\"\" + (col.table + \".\" + col.name if col.table else col.name) + \"\\\"\"  for col in self.col_ops]) + \")\"\n",
    "            \n",
    "class BinaryColumnOp(ColOp):\n",
    "    def __init__(self, s_exp):\n",
    "        self.op = s_exp[2]\n",
    "        self.left_col_op = ColOp.col_op_dispatcher(s_exp[1])\n",
    "        self.right_col_op = ColOp.col_op_dispatcher(s_exp[3])\n",
    "\n",
    "    def rename_ops(self, mapping):\n",
    "        self.left_col_op.rename_ops(mapping)\n",
    "        self.right_col_op.rename_ops(mapping)\n",
    "        \n",
    "    def to_rkt(self, schema):\n",
    "        return \"(BINOP \" + self.left_col_op.to_rkt(schema) + \" \" + self.op + \" \" + self.right_col_op.to_rkt(schema) + \")\"\n",
    "    \n",
    "\n",
    "class AllColumn(ColOp):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def rename_ops(self, mapping):\n",
    "        pass\n",
    "    \n",
    "    def to_rkt(self, schema):\n",
    "        # TODO: how to interpret COUNT(*)\n",
    "        pass\n",
    "    \n",
    "class PredicateOp():\n",
    "    def pred_op_dispatcher(s_exp):\n",
    "        print(s_exp)\n",
    "        if s_exp[0] == 'join_constraint':\n",
    "            print(\"dispatching to Join\")\n",
    "            return JoinPredicate(s_exp)\n",
    "        assert s_exp[0] == \"expr\"\n",
    "        s_exp = find_ultimate_pred(s_exp)\n",
    "        print(\"cleaned s_exp\", s_exp)\n",
    "        if 'and' in s_exp:\n",
    "            print(\"dispatching to And\")\n",
    "            return AndPred(s_exp)\n",
    "        elif 'or' in s_exp:\n",
    "            print(\"dispatching to Or\")\n",
    "            return OrPred(s_exp)\n",
    "        elif s_exp[1][0] == 'unary_operator' and s_exp[1][1] == 'not':\n",
    "            print(\"dispatching to Not\")\n",
    "            return NotPred(s_exp)\n",
    "        elif \"like\" in s_exp:\n",
    "            print(\"dispatching to like\")\n",
    "            return LikePredicate(s_exp)\n",
    "        else:\n",
    "            print(\"dispatching to Predicate\")\n",
    "            return Predicate(s_exp)\n",
    "        \n",
    "\n",
    "class JoinPredicate(PredicateOp):\n",
    "    def __init__(self, s_exp):\n",
    "        assert s_exp[0] == 'join_constraint'\n",
    "        pred_stmt = s_exp[2]\n",
    "        self.op = pred_stmt[2]\n",
    "        self.left_pred_op = ColOp.col_op_dispatcher(pred_stmt[1])\n",
    "        self.right_pred_op = ColOp.col_op_dispatcher(pred_stmt[3])\n",
    "    \n",
    "    def rename_ops(self, mapping):\n",
    "        self.left_pred_op.rename_ops(mapping)\n",
    "        self.right_pred_op.rename_ops(mapping)\n",
    "        \n",
    "    def to_rkt(self, schema):\n",
    "        return \"(BINOP \" + self.left_pred_op.to_rkt(schema) + \" \" + self.op + \" \" + self.right_pred_op.to_rkt(schema) + \")\"\n",
    "\n",
    "def find_ultimate_pred(s_exp):\n",
    "    assert s_exp[0] == \"expr\"\n",
    "    if type(s_exp[1][0]) == list:\n",
    "        return find_ultimate_pred(s_exp[1][0])\n",
    "    else:\n",
    "        return s_exp\n",
    "    \n",
    "class Predicate(PredicateOp):\n",
    "    def __init__(self, s_exp):\n",
    "        assert s_exp[0] == 'expr'\n",
    "        pred_stmt = s_exp\n",
    "        self.left_pred_op = ColOp.col_op_dispatcher(pred_stmt[1])\n",
    "        if pred_stmt[2] == 'not':\n",
    "            self.op = pred_stmt[2:4]\n",
    "            self.right_pred_op = ColOp.col_op_dispatcher(pred_stmt[4])\n",
    "        else:\n",
    "            self.op = pred_stmt[2]\n",
    "            self.right_pred_op = ColOp.col_op_dispatcher(pred_stmt[3])\n",
    "\n",
    "    def rename_ops(self, mapping):\n",
    "        self.left_pred_op.rename_ops(mapping)\n",
    "        self.right_pred_op.rename_ops(mapping)\n",
    "\n",
    "    def to_rkt(self, schema):\n",
    "        return \"(BINOP \" + self.left_pred_op.to_rkt(schema) + \" \" + self.op + \" \" + self.right_pred_op.to_rkt(schema) + \")\"\n",
    "    \n",
    "class LikePredicate(Predicate):\n",
    "    def __init__(self, s_exp):\n",
    "        assert s_exp[0] == 'expr'\n",
    "        self.left_pred_op = ColOp.col_op_dispatcher(s_exp[1])\n",
    "        if s_exp[2] == 'not':\n",
    "            self.like = False\n",
    "            self.pattern = s_exp[4][1][1]\n",
    "        else:\n",
    "            self.like = True\n",
    "            self.pattern = s_exp[3][1][1]\n",
    "        print(\"my pattern is\", self.pattern)\n",
    "    \n",
    "    def rename_ops(self, mapping):\n",
    "        self.left_pred_op.rename_ops(mapping)\n",
    "        \n",
    "    def to_rkt(self, schema):\n",
    "        if self.like:\n",
    "            return \"(LIKEOP \" + self.left_pred_op.to_rkt(schema) + \" \\\"\" + self.pattern + \"\\\")\"\n",
    "        else:\n",
    "            return \"(NOT (LIKEOP \" + self.left_pred_op.to_rkt(schema) + \" \\\"\" + self.pattern + \"\\\"))\"\n",
    "            \n",
    "class AndPred(PredicateOp):\n",
    "    def __init__(self, s_exp):\n",
    "        self.left_pred_op = PredicateOp.pred_op_dispatcher(s_exp[1])\n",
    "        self.right_pred_op = PredicateOp.pred_op_dispatcher(s_exp[3])\n",
    "\n",
    "    def rename_ops(self, mapping):\n",
    "        self.left_pred_op.rename_ops(mapping)\n",
    "        self.right_pred_op.rename_ops(mapping)\n",
    "        \n",
    "    def to_rkt(self, schema):\n",
    "        return \"(AND \" + self.left_pred_op.to_rkt(schema) + \" \" + self.right_pred_op.to_rkt(schema) + \")\"\n",
    "        \n",
    "class OrPred(PredicateOp):\n",
    "    def __init__(self, s_exp):\n",
    "        self.left_pred_op = PredicateOp.pred_op_dispatcher(s_exp[1])\n",
    "        self.right_pred_op = PredicateOp.pred_op_dispatcher(s_exp[3])\n",
    "    \n",
    "    def rename_ops(self, mapping):\n",
    "        self.left_pred_op.rename_ops(mapping)\n",
    "        self.right_pred_op.rename_ops(mapping)\n",
    "        \n",
    "    def to_rkt(self, schema):\n",
    "        return \"(OR \" + self.left_pred_op.to_rkt(schema) + \" \" + self.right_pred_op.to_rkt(schema) + \")\"\n",
    "        \n",
    "def NotPred(PredicateOp):\n",
    "    def __init__(self, s_exp):\n",
    "        pred_stmt = s_exp[2][1][0]\n",
    "        self.op = pred_stmt[2]\n",
    "        self.pred_op = PredOp.pred_op_dispatcher(pred_stmt[1])\n",
    "    \n",
    "    def rename_ops(self, mapping):\n",
    "        self.pred_op.rename_ops(mapping)\n",
    "        \n",
    "    def to_rkt(self, schema):\n",
    "        return \"(NOT \" + self.pred_op.to_rkt(schema) + \")\"\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['expr', ['table_name', ['any_name', 'cand']], '.', ['column_name', ['any_name', 'cand_name']]]\n",
      "dispatching to col name\n",
      "['expr', ['table_name', ['any_name', 'comm']], '.', ['column_name', ['any_name', 'cmte_nm']]]\n",
      "dispatching to col name\n",
      "['join_clause', ['table_or_subquery', ['table_name', ['any_name', 'cand']]], ['join_operator', 'join'], ['table_or_subquery', ['table_name', ['any_name', 'comm']]], 'join_constraint']\n",
      "dispatching to join\n",
      "['table_or_subquery', ['table_name', ['any_name', 'cand']]]\n",
      "dispatching to tbl_ref\n",
      "['table_or_subquery', ['table_name', ['any_name', 'comm']]]\n",
      "dispatching to tbl_ref\n",
      "['expr', ['expr', ['table_name', ['any_name', 'comm']], '.', ['column_name', ['any_name', 'cand_id']]], '=', ['expr', ['table_name', ['any_name', 'cand']], '.', ['column_name', ['any_name', 'cand_id']]]]\n",
      "cleaned s_exp ['expr', ['expr', ['table_name', ['any_name', 'comm']], '.', ['column_name', ['any_name', 'cand_id']]], '=', ['expr', ['table_name', ['any_name', 'cand']], '.', ['column_name', ['any_name', 'cand_id']]]]\n",
      "dispatching to Predicate\n",
      "['expr', ['table_name', ['any_name', 'comm']], '.', ['column_name', ['any_name', 'cand_id']]]\n",
      "dispatching to col name\n",
      "['expr', ['table_name', ['any_name', 'cand']], '.', ['column_name', ['any_name', 'cand_id']]]\n",
      "dispatching to col name\n"
     ]
    }
   ],
   "source": [
    "a = SelectStatement(select_s_exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema2 = {\"indiv_sample_nyc\": {\n",
    "        \"cmte_id\": \"int\", \n",
    "        \"transaction_amt\": \"int\",\n",
    "        \"name\": \"str\"\n",
    "}, \"comm\": {\n",
    "        \"cmte_id\": \"int\", \n",
    "        \"cmte_nm\": \"int\",\n",
    "        \"cand_id\": \"int\"\n",
    "},\n",
    "    \"cand\": {\"cand_name\": \"str\", \"cand_id\": \"int\"}\n",
    "}\n",
    "\n",
    "\n",
    "cand_schema = {\"cand_name\": \"str\", \"cand_id\": \"int\"}\n",
    "comm_schema = {\"cmte_nm\": \"int\", \"cand_id\": \"int\"}\n",
    "schema1 = {'cand': cand_schema, 'comm': comm_schema}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "returning [{'cand_name', 'cand.cand_name'}, {'cand_id', 'cand.cand_id'}]\n",
      "returning [{'cmte_id', 'comm.cmte_id'}, {'comm.cmte_nm', 'cmte_nm'}, {'cand_id', 'comm.cand_id'}]\n",
      "Inferring join, returning [{'cand_name', 'cand.cand_name'}, {'cand_id', 'cand.cand_id'}, {'cmte_id', 'comm.cmte_id'}, {'comm.cmte_nm', 'cmte_nm'}, {'comm.cand_id'}]\n",
      "Inferring select, returning [{'cand_name'}, {'cmte_nm'}]\n",
      "returning [{'cand_name', 'cand.cand_name'}, {'cand_id', 'cand.cand_id'}]\n",
      "returning [{'cmte_id', 'comm.cmte_id'}, {'comm.cmte_nm', 'cmte_nm'}, {'cand_id', 'comm.cand_id'}]\n",
      "returning [{'cand_name', 'cand.cand_name'}, {'cand_id', 'cand.cand_id'}]\n",
      "returning [{'cmte_id', 'comm.cmte_id'}, {'comm.cmte_nm', 'cmte_nm'}, {'cand_id', 'comm.cand_id'}]\n",
      "Inferring join, returning [{'cand_name', 'cand.cand_name'}, {'cand_id', 'cand.cand_id'}, {'cmte_id', 'comm.cmte_id'}, {'comm.cmte_nm', 'cmte_nm'}, {'comm.cand_id'}]\n",
      "returning [{'cand_name', 'cand.cand_name'}, {'cand_id', 'cand.cand_id'}]\n",
      "returning [{'cmte_id', 'comm.cmte_id'}, {'comm.cmte_nm', 'cmte_nm'}, {'cand_id', 'comm.cand_id'}]\n",
      "My mapping from join:\n",
      "{'cand.cand_id': 't.cand_id',\n",
      " 'cand.cand_name': 't.cand_name',\n",
      " 'cand_id': 't.cand_id',\n",
      " 'cand_name': 't.cand_name',\n",
      " 'cmte_id': 't.cmte_id',\n",
      " 'cmte_nm': 't.cmte_nm',\n",
      " 'comm.cand_id': 't.cand_id_2',\n",
      " 'comm.cmte_id': 't.cmte_id',\n",
      " 'comm.cmte_nm': 't.cmte_nm'}\n",
      "returning [{'cand_name', 'cand.cand_name'}, {'cand_id', 'cand.cand_id'}]\n",
      "returning [{'cmte_id', 'comm.cmte_id'}, {'comm.cmte_nm', 'cmte_nm'}, {'cand_id', 'comm.cand_id'}]\n",
      "Inferring join, returning [{'cand_name', 'cand.cand_name'}, {'cand_id', 'cand.cand_id'}, {'cmte_id', 'comm.cmte_id'}, {'comm.cmte_nm', 'cmte_nm'}, {'comm.cand_id'}]\n",
      "My child old names are [{'cand_name', 'cand.cand_name'}, {'cand_id', 'cand.cand_id'}, {'cmte_id', 'comm.cmte_id'}, {'comm.cmte_nm', 'cmte_nm'}, {'comm.cand_id'}]\n",
      "my old names are [{'cand_name'}, {'cmte_nm'}]\n",
      "My mapping is [Select t_2]:\n",
      "{'cand_name': 't_2.cand_name', 'cmte_nm': 't_2.cmte_nm'}\n"
     ]
    }
   ],
   "source": [
    "a = a.rename(schema2, [])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'(AS (SELECT (VALS \"t.cand_name\" \"t.cmte_nm\")\\nFROM (AS (JOIN (AS (NAMED cand)\\n[\"cand\" (list \"cand_name\" \"cand_id\")]) (AS (NAMED comm)\\n[\"comm\" (list \"cmte_id\" \"cmte_nm\" \"cand_id\")]) )\\n[\"t\" (list \"cand_name\" \"cand_id\" \"cmte_id\" \"cmte_nm\" \"cand_id_2\")])\\nWHERE (BINOP \"t.cand_id_2\" = \"t.cand_id\")  )\\n[\"t_2\" (list \"cand_name\" \"cmte_nm\")])'"
      ]
     },
     "execution_count": 440,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = a.to_rkt(schema2)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(AS (SELECT (VALS \"t.cand_name\" \"t.cmte_nm\")\n",
      "FROM (AS (JOIN (AS (NAMED cand)\n",
      "[\"cand\" (list \"cand_name\" \"cand_id\")]) (AS (NAMED comm)\n",
      "[\"comm\" (list \"cmte_id\" \"cmte_nm\" \"cand_id\")]) )\n",
      "[\"t\" (list \"cand_name\" \"cand_id\" \"cmte_id\" \"cmte_nm\" \"cand_id_2\")])\n",
      "WHERE (BINOP \"t.cand_id_2\" = \"t.cand_id\")  )\n",
      "[\"t_2\" (list \"cand_name\" \"cmte_nm\")])\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "returning [{'cand_name', 'cand.cand_name'}, {'cand_id', 'cand.cand_id'}]\n",
      "returning [{'cmte_id', 'comm.cmte_id'}, {'comm.cmte_nm', 'cmte_nm'}, {'cand_id', 'comm.cand_id'}]\n",
      "Inferring join, returning [{'cand_name', 'cand.cand_name'}, {'cand_id', 'cand.cand_id'}, {'cmte_id', 'comm.cmte_id'}, {'comm.cmte_nm', 'cmte_nm'}, {'comm.cand_id'}]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'cand.cand_name', 'cand_name'},\n",
       " {'cand.cand_id', 'cand_id'},\n",
       " {'cmte_id', 'comm.cmte_id'},\n",
       " {'cmte_nm', 'comm.cmte_nm'},\n",
       " {'comm.cand_id'}]"
      ]
     },
     "execution_count": 442,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.table.subquery_tree.table.infer_out_schema(schema2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for every rename call, should distinguish\n",
    "1. get children old col names\n",
    "2. get my own old names\n",
    "3. rename child. This returns us a child mapping of old to new\n",
    "4. rename_ops with child mapping (it always uses tehc hild mapping) (RENAME OPS ONLY TAKES MAPPING + self)\n",
    "5. invent my new names\n",
    "6. create my mappings from my old to new names\n",
    "7. rename having + order colops using parent mapping\n",
    "8. wrap and return renamed table + mappings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-326-def6d4ca4b53>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-326-def6d4ca4b53>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    (AS (SELECT (VALS \"temp_col_name_0\" \"temp_col_name_1\")\u001b[0m\n\u001b[0m                      ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "(AS (SELECT (VALS \"c_0\" \"c_1\")\n",
    "    FROM (AS (JOIN (AS (NAMED cand)\n",
    "                        [\"cand_0\" (list \"cand_name\" \"cand_id\")]) \n",
    "                    (AS (NAMED comm)\n",
    "                        [\"comm_0\" (list \"cmte_id\" \"cmte_nm\" \"cand_id\")]) )\n",
    "        [\"t_0\" (list \"cand_name_0\" \"cand_id_0\" \"cmte_id_0\" \"cmte_nm_0\" \"cand_id_1\")])\n",
    "    WHERE (BINOP \"t_0.cand_id_1\" = \"t_0.cand_id_0\")  )\n",
    "    [\"t_1\" (list \"c_0\" \"c_1\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-290-eae5f93fb052>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-290-eae5f93fb052>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    (AS (JOIN (AS (NAMED cand)\u001b[0m\n\u001b[0m                         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "(AS (JOIN (AS (NAMED cand)\n",
    "            [\"cand_0\" (list \"cand_name\" \"cand_id\")]) \n",
    "         (AS (NAMED comm)\n",
    "            [\"comm_0\" (list \"cmte_id\" \"cmte_nm\" \"cand_id\")]) )\n",
    "[\"t_0\" (list \"cand_name_0\" \"cand_name_0\" \"cand_id_0\" \"cand_id_0\" \"cmte_id_0\" \"cmte_id_0\" \"cmte_nm_0\" \"cmte_nm_0\" \"cand_id_1\" \"cand_id_1\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(AS (SELECT (VALS \"tbl_1.cand_name\" \"tbl_1.cmte_nm\")\n",
    "    FROM (AS (JOIN (AS (NAMED cand)\n",
    "                    [\"cand\" (list \"cand.cand_name\" \"cand.cand_id\")]) \n",
    "                  (AS (NAMED comm)\n",
    "                    [\"comm\" (list \"comm.cmte_id\" \"comm.cmte_nm\" \"comm.cand_id\")]) )\n",
    "            [\"tbl_0\" (list \"cand.cand_name\" \"cand.cand_id\" \"comm.cmte_id\" \"comm.cmte_nm\" \"comm.cand_id2\")])\n",
    "    WHERE (BINOP \"comm.cand_id\" = \"tbl_0.cand_id\")  )\n",
    "[\"tbl_1\" (list \"tbl_0.cand_name\" \"tbl_0.cand_id\" \"tbl_0.cmte_id\" \"tbl_0.cmte_nm\" \"temp_col_name_4\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(SELECT (VALS \"tbl_1.cmte_id\" \"tbl_1.total_amount\" \"tbl_1.num_donations\" \"tbl_1.cmte_nm\")\n",
    "    FROM (AS (SELECT (VALS \"t3.cmte_id\" \"t3.transaction_amt\" \"t3.name\" \"t3.cmte_id2\" \"t3.cmte_nm\")\n",
    "        FROM (AS (JOIN (AS (NAMED indiv_sample_nyc)\n",
    "            [\"indiv_sample_nyc\" (list \"indiv_sample_nyc.cmte_id\" \"indiv_sample_nyc.transaction_amt\" \"indiv_sample_nyc.name\")]) (AS (NAMED comm)\n",
    "            [\"comm\" (list \"comm.cmte_id\" \"comm.cmte_nm\")]) )\n",
    "        [\"tbl_0\" (list \"indiv_sample_nyc.cmte_id\" \"indiv_sample_nyc.transaction_amt\" \"indiv_sample_nyc.name\" \"comm.cmte_id2\" \"comm.cmte_nm\")])\n",
    "        WHERE (BINOP \"tbl_0.cmte_id\" == \"comm.cmte_id\")  )\n",
    "    [\"t3\" (list \"tbl_0.cmte_id\" \"tbl_0.transaction_amt\" \"tbl_0.name\" \"temp_col_name_3\" \"tbl_0.cmte_nm\")])\n",
    "WHERE (AND (AND (LIKEOP \"name\" \"'%trump%'\") (LIKEOP \"name\" \"'%donald%'\")) (NOT (LIKEOP \"name\" \"'%inc%'\"))) \n",
    "GROUP-BY (list \"\"cmte_id\"\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: renamed columns featured in having or order by -> wrap in select\n",
    "# SELECT *\n",
    "# (SELECT \n",
    "#     cmte_id,\n",
    "#     SUM(transaction_amt) as total_amount,\n",
    "#     COUNT(*) as num_donations,\n",
    "#     cmte_nm\n",
    "# FROM \n",
    "#         (SELECT *\n",
    "#         FROM indiv_sample_nyc, comm\n",
    "#         WHERE indiv_sample_nyc.cmte_id == comm.cmte_id) as t3\n",
    "# WHERE  (name LIKE '%TRUMP%') AND  (name LIKE '%DONALD%') AND  (name NOT LIKE '%INC%')\n",
    "# GROUP BY cmte_id) AS [a, b, c]\n",
    "# WHERE c > 10\n",
    "# ORDER BY c DESC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = SelectStatement(test3[1][1][1])\n",
    "b = b.rename(schema1, 0)[0]\n",
    "print(b.to_rkt(schema1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b.table.subquery_tree.table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Finish to do items within the classes, ensure it works\n",
    "2. to rkt functions\n",
    "3. testing\n",
    "4. python testing on limit/order, LIKEOP (then remove for rkt tree)\n",
    "5. error logging feedback\n",
    "6. dockerization\n",
    "\n",
    "nice to have\n",
    "- fstrings for to_rkt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SELECT \n",
    "    cmte_id,\n",
    "    SUM(transaction_amt) as total_amount,\n",
    "    COUNT(*) as num_donations,\n",
    "    cmte_nm\n",
    "FROM \n",
    "        SELECT *\n",
    "        FROM indiv_sample_nyc, comm\n",
    "        WHERE indiv_sample_nyc.cmte_id == comm.cmte_id\n",
    "WHERE  (name LIKE '%TRUMP%') AND  (name LIKE '%DONALD%') AND  (name NOT LIKE '%INC%') GROUP BY cmte_id\n",
    "ORDER BY total_amount DESC\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
